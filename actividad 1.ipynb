{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import chardet\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cargar la base de datos de nombre \"ejemplo data.csv\". En esta parte recomendamos explorar las diferentes opciones de read que tiene disponible la libreria Pandas, \n",
    "#identificando los argumentos disponibles en cada una de ellas.\n",
    "\n",
    "file_path = \"ejemplo_data.csv\"\n",
    "df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primeras filas del dataset:\n",
      "       ID        Nombre         2016          2017 Crecimiento Unidades  \\\n",
      "0   10002     Verde Mar  $125,000.00    $162500.00      30.00%      500   \n",
      "1  552278  Manantial sa  $920,000.00  $101,2000.00      10.00%      700   \n",
      "2   23477          ACME   $50,000.00      62500.00      25.00%      125   \n",
      "3   24900     Andes sur  $350,000.00     490000.00       4.00%       75   \n",
      "4  651029     San Pablo   $15,000.00     $12750.00     -15.00%       No   \n",
      "\n",
      "        fecha  Activo  \n",
      "0   1-10-2015       1  \n",
      "1   6-23-2014       0  \n",
      "2   3-12-2016       1  \n",
      "3  10-28-2015       1  \n",
      "4   2-15-2014       0  \n"
     ]
    }
   ],
   "source": [
    "print(\"Primeras filas del dataset:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Información general del dataset:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5 entries, 0 to 4\n",
      "Data columns (total 8 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   ID           5 non-null      int64 \n",
      " 1   Nombre       5 non-null      object\n",
      " 2   2016         5 non-null      object\n",
      " 3   2017         5 non-null      object\n",
      " 4   Crecimiento  5 non-null      object\n",
      " 5   Unidades     5 non-null      object\n",
      " 6   fecha        5 non-null      object\n",
      " 7   Activo       5 non-null      int64 \n",
      "dtypes: int64(2), object(6)\n",
      "memory usage: 452.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nInformación general del dataset:\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Estado de las variables después de las transformaciones:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5 entries, 0 to 4\n",
      "Data columns (total 8 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   ID           5 non-null      int64 \n",
      " 1   Nombre       5 non-null      object\n",
      " 2   2016         5 non-null      object\n",
      " 3   2017         5 non-null      object\n",
      " 4   Crecimiento  5 non-null      object\n",
      " 5   Unidades     5 non-null      object\n",
      " 6   fecha        5 non-null      object\n",
      " 7   Activo       5 non-null      bool  \n",
      "dtypes: bool(1), int64(1), object(6)\n",
      "memory usage: 417.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "#Utilizando la función astype transforme el atributo \"ID\" a entero y el atributo \"Activo\" a booleano.\n",
    "if 'ID' in df.columns and 'Activo' in df.columns:\n",
    "    df['ID'] = df['ID'].astype(int)\n",
    "    df['Activo'] = df['Activo'].astype(bool)\n",
    "    print(\"\\nEstado de las variables después de las transformaciones:\")\n",
    "    df.info()\n",
    "else:\n",
    "    print(\"\\nLas columnas 'ID' y 'Activo' no están presentes en el dataset.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo cargado correctamente con la codificación 'latin1'.\n",
      "\n",
      "Primeras filas del DataFrame cargado:\n",
      "  InvoiceNo StockCode                          Description  Quantity  \\\n",
      "0    536365    85123A   WHITE HANGING HEART T-LIGHT HOLDER         6   \n",
      "1    536365     71053                  WHITE METAL LANTERN         6   \n",
      "2    536365    84406B       CREAM CUPID HEARTS COAT HANGER         8   \n",
      "3    536365    84029G  KNITTED UNION FLAG HOT WATER BOTTLE         6   \n",
      "4    536365    84029E       RED WOOLLY HOTTIE WHITE HEART.         6   \n",
      "\n",
      "      InvoiceDate  UnitPrice  CustomerID         Country  \n",
      "0  12/1/2010 8:26       2.55     17850.0  United Kingdom  \n",
      "1  12/1/2010 8:26       3.39     17850.0  United Kingdom  \n",
      "2  12/1/2010 8:26       2.75     17850.0  United Kingdom  \n",
      "3  12/1/2010 8:26       3.39     17850.0  United Kingdom  \n",
      "4  12/1/2010 8:26       3.39     17850.0  United Kingdom  \n"
     ]
    }
   ],
   "source": [
    "# Manejo de valores faltantes durante la lectura con codificación especificada\n",
    "try:\n",
    "    df_ecommerce = pd.read_csv(file_path2, encoding='latin1', na_values=[\"N/A\", \"null\", \"missing\"])\n",
    "    print(\"Archivo cargado correctamente con la codificación 'latin1'.\")\n",
    "except UnicodeDecodeError:\n",
    "    print(\"Error al leer el archivo con la codificación 'latin1'. Intenta con otra codificación.\")\n",
    "except Exception as e:\n",
    "    print(f\"Otro error ocurrió al leer el archivo: {e}\")\n",
    "\n",
    "try:\n",
    "    print(\"\\nPrimeras filas del DataFrame cargado:\")\n",
    "    print(df_ecommerce.head())\n",
    "except NameError:\n",
    "    print(\"El DataFrame no se pudo cargar correctamente.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar solo las primeras filas\n",
    "df_ecommerce = pd.read_csv(file_path2, nrows=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primeras filas del dataset:\n",
      "   InvoiceNo StockCode                          Description  Quantity  \\\n",
      "0     536365    85123A   WHITE HANGING HEART T-LIGHT HOLDER         6   \n",
      "1     536365     71053                  WHITE METAL LANTERN         6   \n",
      "2     536365    84406B       CREAM CUPID HEARTS COAT HANGER         8   \n",
      "3     536365    84029G  KNITTED UNION FLAG HOT WATER BOTTLE         6   \n",
      "4     536365    84029E       RED WOOLLY HOTTIE WHITE HEART.         6   \n",
      "\n",
      "      InvoiceDate  UnitPrice  CustomerID         Country  \n",
      "0  12/1/2010 8:26       2.55       17850  United Kingdom  \n",
      "1  12/1/2010 8:26       3.39       17850  United Kingdom  \n",
      "2  12/1/2010 8:26       2.75       17850  United Kingdom  \n",
      "3  12/1/2010 8:26       3.39       17850  United Kingdom  \n",
      "4  12/1/2010 8:26       3.39       17850  United Kingdom  \n"
     ]
    }
   ],
   "source": [
    "print(\"Primeras filas del dataset:\")\n",
    "print(df_ecommerce.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tipos de variables en la base de datos (usando df.info()):\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100 entries, 0 to 99\n",
      "Data columns (total 8 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   InvoiceNo    100 non-null    int64  \n",
      " 1   StockCode    100 non-null    object \n",
      " 2   Description  100 non-null    object \n",
      " 3   Quantity     100 non-null    int64  \n",
      " 4   InvoiceDate  100 non-null    object \n",
      " 5   UnitPrice    100 non-null    float64\n",
      " 6   CustomerID   100 non-null    int64  \n",
      " 7   Country      100 non-null    object \n",
      "dtypes: float64(1), int64(3), object(4)\n",
      "memory usage: 6.4+ KB\n",
      "\n",
      "Tipos de variables en la base de datos (usando df.dtypes):\n",
      "InvoiceNo        int64\n",
      "StockCode       object\n",
      "Description     object\n",
      "Quantity         int64\n",
      "InvoiceDate     object\n",
      "UnitPrice      float64\n",
      "CustomerID       int64\n",
      "Country         object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "#Identifique los tipos de varibles que hay disponibles en la base de datos (df.types o df.info()).\n",
    "print(\"Tipos de variables en la base de datos (usando df.info()):\")\n",
    "df_ecommerce.info()\n",
    "\n",
    "print(\"\\nTipos de variables en la base de datos (usando df.dtypes):\")\n",
    "print(df_ecommerce.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La columna 'InvoiceNo' se transformó a entero.\n",
      "La columna 'Description' se transformó a string.\n",
      "\n",
      "Estado de las variables después de las transformaciones:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100 entries, 0 to 99\n",
      "Data columns (total 8 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   InvoiceNo    100 non-null    int64  \n",
      " 1   StockCode    100 non-null    object \n",
      " 2   Description  100 non-null    object \n",
      " 3   Quantity     100 non-null    int64  \n",
      " 4   InvoiceDate  100 non-null    object \n",
      " 5   UnitPrice    100 non-null    float64\n",
      " 6   CustomerID   100 non-null    int64  \n",
      " 7   Country      100 non-null    object \n",
      "dtypes: float64(1), int64(3), object(4)\n",
      "memory usage: 6.4+ KB\n"
     ]
    }
   ],
   "source": [
    "# Utilizando la función astype transforme el atributo \"InvoiceNo\" a entero y el atributo \"Description\" a string. Vuelva a consultar el estado de las variables.\n",
    "if 'InvoiceNo' in df_ecommerce.columns and 'Description' in df_ecommerce.columns:\n",
    "    try:\n",
    "        df_ecommerce['InvoiceNo'] = df_ecommerce['InvoiceNo'].astype(int)\n",
    "        print(\"La columna 'InvoiceNo' se transformó a entero.\")\n",
    "    except ValueError as e:\n",
    "        print(f\"No se pudo transformar 'InvoiceNo' a entero: {e}\")\n",
    "\n",
    "    # Transformar 'Description' a string\n",
    "    df_ecommerce['Description'] = df_ecommerce['Description'].astype(str)\n",
    "    print(\"La columna 'Description' se transformó a string.\")\n",
    "\n",
    "    # Consultar nuevamente el estado de las variables\n",
    "    print(\"\\nEstado de las variables después de las transformaciones:\")\n",
    "    df_ecommerce.info()\n",
    "else:\n",
    "    print(\"\\nLas columnas 'InvoiceNo' y/o 'Description' no están presentes en el DataFrame.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La columna 'Quantity' se transformó a entero.\n",
      "La columna 'UnitPrice' se transformó a flotante.\n",
      "\n",
      "Estado de las variables después de las transformaciones:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100 entries, 0 to 99\n",
      "Data columns (total 8 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   InvoiceNo    100 non-null    int64  \n",
      " 1   StockCode    100 non-null    object \n",
      " 2   Description  100 non-null    object \n",
      " 3   Quantity     100 non-null    int64  \n",
      " 4   InvoiceDate  100 non-null    object \n",
      " 5   UnitPrice    100 non-null    float64\n",
      " 6   CustomerID   100 non-null    int64  \n",
      " 7   Country      100 non-null    object \n",
      "dtypes: float64(1), int64(3), object(4)\n",
      "memory usage: 6.4+ KB\n"
     ]
    }
   ],
   "source": [
    "#Convierta el atributo \"Quantity\" a entero y \"UnitPrice\" a flotante.\n",
    "if 'Quantity' in df_ecommerce.columns and 'UnitPrice' in df_ecommerce.columns:\n",
    "    try:\n",
    "        df_ecommerce['Quantity'] = df_ecommerce['Quantity'].astype(int)\n",
    "        print(\"La columna 'Quantity' se transformó a entero.\")\n",
    "    except ValueError as e:\n",
    "        print(f\"No se pudo transformar 'Quantity' a entero: {e}\")\n",
    "    try:\n",
    "        df_ecommerce['UnitPrice'] = df_ecommerce['UnitPrice'].astype(float)\n",
    "        print(\"La columna 'UnitPrice' se transformó a flotante.\")\n",
    "    except ValueError as e:\n",
    "        print(f\"No se pudo transformar 'UnitPrice' a flotante: {e}\")\n",
    "\n",
    "    print(\"\\nEstado de las variables después de las transformaciones:\")\n",
    "    df_ecommerce.info()\n",
    "else:\n",
    "    print(\"\\nLas columnas 'Quantity' y/o 'UnitPrice' no están presentes en el DataFrame.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La columna 'InvoiceDate' se ha separado en 'Fecha' y 'Hora'.\n",
      "\n",
      "Primeras filas del DataFrame actualizado:\n",
      "   InvoiceNo StockCode                          Description  Quantity  \\\n",
      "0     536365    85123A   WHITE HANGING HEART T-LIGHT HOLDER         6   \n",
      "1     536365     71053                  WHITE METAL LANTERN         6   \n",
      "2     536365    84406B       CREAM CUPID HEARTS COAT HANGER         8   \n",
      "3     536365    84029G  KNITTED UNION FLAG HOT WATER BOTTLE         6   \n",
      "4     536365    84029E       RED WOOLLY HOTTIE WHITE HEART.         6   \n",
      "\n",
      "          InvoiceDate  UnitPrice  CustomerID         Country       Fecha  \\\n",
      "0 2010-12-01 08:26:00       2.55       17850  United Kingdom  2010-12-01   \n",
      "1 2010-12-01 08:26:00       3.39       17850  United Kingdom  2010-12-01   \n",
      "2 2010-12-01 08:26:00       2.75       17850  United Kingdom  2010-12-01   \n",
      "3 2010-12-01 08:26:00       3.39       17850  United Kingdom  2010-12-01   \n",
      "4 2010-12-01 08:26:00       3.39       17850  United Kingdom  2010-12-01   \n",
      "\n",
      "       Hora  TotalAmount  \n",
      "0  08:26:00        15.30  \n",
      "1  08:26:00        20.34  \n",
      "2  08:26:00        22.00  \n",
      "3  08:26:00        20.34  \n",
      "4  08:26:00        20.34  \n"
     ]
    }
   ],
   "source": [
    "#La columna \"InvoiceDate\" contiene un string que representa \"fecha-hora\", separe la columna en dos columnas que representen cada atributo por separado.\n",
    "if 'InvoiceDate' in df_ecommerce.columns:\n",
    "    try:\n",
    "        df_ecommerce['InvoiceDate'] = pd.to_datetime(df_ecommerce['InvoiceDate'])\n",
    "        df_ecommerce['Fecha'] = df_ecommerce['InvoiceDate'].dt.date\n",
    "        df_ecommerce['Hora'] = df_ecommerce['InvoiceDate'].dt.time\n",
    "\n",
    "        print(\"La columna 'InvoiceDate' se ha separado en 'Fecha' y 'Hora'.\")\n",
    "    except Exception as e:\n",
    "        print(f\"No se pudo procesar la columna 'InvoiceDate': {e}\")\n",
    "else:\n",
    "    print(\"La columna 'InvoiceDate' no está presente en el DataFrame.\")\n",
    "\n",
    "print(\"\\nPrimeras filas del DataFrame actualizado:\")\n",
    "print(df_ecommerce.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se ha añadido la columna 'TotalAmount', que representa el monto total para cada boleta.\n",
      "\n",
      "Primeras filas del DataFrame actualizado:\n",
      "   InvoiceNo StockCode                          Description  Quantity  \\\n",
      "0     536365    85123A   WHITE HANGING HEART T-LIGHT HOLDER         6   \n",
      "1     536365     71053                  WHITE METAL LANTERN         6   \n",
      "2     536365    84406B       CREAM CUPID HEARTS COAT HANGER         8   \n",
      "3     536365    84029G  KNITTED UNION FLAG HOT WATER BOTTLE         6   \n",
      "4     536365    84029E       RED WOOLLY HOTTIE WHITE HEART.         6   \n",
      "\n",
      "          InvoiceDate  UnitPrice  CustomerID         Country       Fecha  \\\n",
      "0 2010-12-01 08:26:00       2.55       17850  United Kingdom  2010-12-01   \n",
      "1 2010-12-01 08:26:00       3.39       17850  United Kingdom  2010-12-01   \n",
      "2 2010-12-01 08:26:00       2.75       17850  United Kingdom  2010-12-01   \n",
      "3 2010-12-01 08:26:00       3.39       17850  United Kingdom  2010-12-01   \n",
      "4 2010-12-01 08:26:00       3.39       17850  United Kingdom  2010-12-01   \n",
      "\n",
      "       Hora  TotalAmount  \n",
      "0  08:26:00        15.30  \n",
      "1  08:26:00        20.34  \n",
      "2  08:26:00        22.00  \n",
      "3  08:26:00        20.34  \n",
      "4  08:26:00        20.34  \n",
      "La base de datos procesada ha sido exportada exitosamente como 'ecommerce_data_procesada.csv'.\n"
     ]
    }
   ],
   "source": [
    "#Añada una nueva columna que represente el monto total para cada boleta.\n",
    "if 'Quantity' in df_ecommerce.columns and 'UnitPrice' in df_ecommerce.columns:\n",
    "    df_ecommerce['TotalAmount'] = df_ecommerce['Quantity'] * df_ecommerce['UnitPrice']\n",
    "    print(\"Se ha añadido la columna 'TotalAmount', que representa el monto total para cada boleta.\")\n",
    "else:\n",
    "    print(\"Las columnas 'Quantity' y/o 'UnitPrice' no están presentes en el DataFrame.\")\n",
    "print(\"\\nPrimeras filas del DataFrame actualizado:\")\n",
    "print(df_ecommerce.head())\n",
    "output_file = \"ecommerce_data_procesada.csv\"\n",
    "\n",
    "try:\n",
    "    df_ecommerce.to_csv(output_file, index=False)  # index=False para evitar incluir el índice como columna\n",
    "    print(f\"La base de datos procesada ha sido exportada exitosamente como '{output_file}'.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error al exportar el archivo: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columnas disponibles en el DataFrame:\n",
      "Index(['InvoiceNo', 'StockCode', 'Description', 'Quantity', 'InvoiceDate',\n",
      "       'UnitPrice', 'CustomerID', 'Country', 'Fecha', 'Hora', 'TotalAmount'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(\"Columnas disponibles en el DataFrame:\")\n",
    "print(df_ecommerce.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ecommerce.rename(columns=lambda x: x.strip(), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Exploración de funciones groupby, sort values, set index, sample, pivot, reset index y merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agrupación por 'InvoiceNo' y suma de 'TotalAmount':\n",
      "InvoiceNo\n",
      "536365    139.12\n",
      "536366     22.20\n",
      "536367    278.73\n",
      "536368     70.05\n",
      "536369     17.85\n",
      "Name: TotalAmount, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#groupby: Agrupar datos y realizar operaciones\n",
    "print(\"Agrupación por 'InvoiceNo' y suma de 'TotalAmount':\")\n",
    "grouped = df_ecommerce.groupby('InvoiceNo')['TotalAmount'].sum()\n",
    "print(grouped.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ordenar por 'TotalAmount' en orden descendente:\n",
      "    InvoiceNo StockCode                        Description  Quantity  \\\n",
      "65     536374     21258         VICTORIAN SEWING BOX LARGE        32   \n",
      "46     536371     22086    PAPER CHAIN KIT 50'S CHRISTMAS         80   \n",
      "82     536376     22114  HOT WATER BOTTLE TEA AND SYMPATHY        48   \n",
      "83     536376     21733   RED HANGING HEART T-LIGHT HOLDER        64   \n",
      "26     536370     22728          ALARM CLOCK BAKELIKE PINK        24   \n",
      "\n",
      "           InvoiceDate  UnitPrice  CustomerID         Country       Fecha  \\\n",
      "65 2010-12-01 09:09:00      10.95       15100  United Kingdom  2010-12-01   \n",
      "46 2010-12-01 09:00:00       2.55       13748  United Kingdom  2010-12-01   \n",
      "82 2010-12-01 09:32:00       3.45       15291  United Kingdom  2010-12-01   \n",
      "83 2010-12-01 09:32:00       2.55       15291  United Kingdom  2010-12-01   \n",
      "26 2010-12-01 08:45:00       3.75       12583          France  2010-12-01   \n",
      "\n",
      "        Hora  TotalAmount  \n",
      "65  09:09:00        350.4  \n",
      "46  09:00:00        204.0  \n",
      "82  09:32:00        165.6  \n",
      "83  09:32:00        163.2  \n",
      "26  08:45:00         90.0  \n"
     ]
    }
   ],
   "source": [
    "# sort_values: Ordenar datos por una o más columnas\n",
    "print(\"\\nOrdenar por 'TotalAmount' en orden descendente:\")\n",
    "sorted_df = df_ecommerce.sort_values(by='TotalAmount', ascending=False)\n",
    "print(sorted_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3. Establecer 'InvoiceNo' como índice:\n",
      "          StockCode                          Description  Quantity  \\\n",
      "InvoiceNo                                                            \n",
      "536365       85123A   WHITE HANGING HEART T-LIGHT HOLDER         6   \n",
      "536365        71053                  WHITE METAL LANTERN         6   \n",
      "536365       84406B       CREAM CUPID HEARTS COAT HANGER         8   \n",
      "536365       84029G  KNITTED UNION FLAG HOT WATER BOTTLE         6   \n",
      "536365       84029E       RED WOOLLY HOTTIE WHITE HEART.         6   \n",
      "\n",
      "                  InvoiceDate  UnitPrice  CustomerID         Country  \\\n",
      "InvoiceNo                                                              \n",
      "536365    2010-12-01 08:26:00       2.55       17850  United Kingdom   \n",
      "536365    2010-12-01 08:26:00       3.39       17850  United Kingdom   \n",
      "536365    2010-12-01 08:26:00       2.75       17850  United Kingdom   \n",
      "536365    2010-12-01 08:26:00       3.39       17850  United Kingdom   \n",
      "536365    2010-12-01 08:26:00       3.39       17850  United Kingdom   \n",
      "\n",
      "                Fecha      Hora  TotalAmount  \n",
      "InvoiceNo                                     \n",
      "536365     2010-12-01  08:26:00        15.30  \n",
      "536365     2010-12-01  08:26:00        20.34  \n",
      "536365     2010-12-01  08:26:00        22.00  \n",
      "536365     2010-12-01  08:26:00        20.34  \n",
      "536365     2010-12-01  08:26:00        20.34  \n"
     ]
    }
   ],
   "source": [
    "# set_index: Establecer una columna como índice\n",
    "print(\"\\nEstablecer 'InvoiceNo' como índice:\")\n",
    "indexed_df = df_ecommerce.set_index('InvoiceNo')\n",
    "print(indexed_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "4. Muestra aleatoria de 5 filas:\n",
      "    InvoiceNo StockCode                         Description  Quantity  \\\n",
      "70     536375     37370          RETRO COFFEE MUGS ASSORTED         6   \n",
      "6      536365     21730   GLASS STAR FROSTED T-LIGHT HOLDER         6   \n",
      "81     536375     21730   GLASS STAR FROSTED T-LIGHT HOLDER         6   \n",
      "0      536365    85123A  WHITE HANGING HEART T-LIGHT HOLDER         6   \n",
      "13     536367     22310             IVORY KNITTED MUG COSY          6   \n",
      "\n",
      "           InvoiceDate  UnitPrice  CustomerID         Country       Fecha  \\\n",
      "70 2010-12-01 09:32:00       1.06       17850  United Kingdom  2010-12-01   \n",
      "6  2010-12-01 08:26:00       4.25       17850  United Kingdom  2010-12-01   \n",
      "81 2010-12-01 09:32:00       4.25       17850  United Kingdom  2010-12-01   \n",
      "0  2010-12-01 08:26:00       2.55       17850  United Kingdom  2010-12-01   \n",
      "13 2010-12-01 08:34:00       1.65       13047  United Kingdom  2010-12-01   \n",
      "\n",
      "        Hora  TotalAmount  \n",
      "70  09:32:00         6.36  \n",
      "6   08:26:00        25.50  \n",
      "81  09:32:00        25.50  \n",
      "0   08:26:00        15.30  \n",
      "13  08:34:00         9.90  \n"
     ]
    }
   ],
   "source": [
    "# sample: Tomar una muestra aleatoria de datos\n",
    "print(\"\\nMuestra aleatoria de 5 filas:\")\n",
    "sample_df = df_ecommerce.sample(5)\n",
    "print(sample_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Pivot para obtener 'Quantity' por 'InvoiceNo':\n",
      "           Quantity\n",
      "InvoiceNo          \n",
      "536365           40\n",
      "536366           12\n",
      "536367           83\n",
      "536368           15\n",
      "536369            3\n"
     ]
    }
   ],
   "source": [
    "# pivot: Reorganizar datos en formato tabla dinámica\n",
    "if 'InvoiceNo' in df_ecommerce.columns and 'Quantity' in df_ecommerce.columns:\n",
    "    print(\"\\nPivot para obtener 'Quantity' por 'InvoiceNo':\")\n",
    "    pivot_df = df_ecommerce.pivot_table(values='Quantity', index='InvoiceNo', aggfunc='sum')\n",
    "    print(pivot_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Restablecer el índice del DataFrame agrupado:\n",
      "   InvoiceNo  TotalAmount\n",
      "0     536365       139.12\n",
      "1     536366        22.20\n",
      "2     536367       278.73\n",
      "3     536368        70.05\n",
      "4     536369        17.85\n"
     ]
    }
   ],
   "source": [
    "# reset_index: Restablecer el índice del DataFrame\n",
    "print(\"\\nRestablecer el índice del DataFrame agrupado:\")\n",
    "reset_df = grouped.reset_index()\n",
    "print(reset_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Merge del DataFrame original con datos adicionales:\n",
      "   InvoiceNo StockCode                          Description  Quantity  \\\n",
      "0     536365    85123A   WHITE HANGING HEART T-LIGHT HOLDER         6   \n",
      "1     536365     71053                  WHITE METAL LANTERN         6   \n",
      "2     536365    84406B       CREAM CUPID HEARTS COAT HANGER         8   \n",
      "3     536365    84029G  KNITTED UNION FLAG HOT WATER BOTTLE         6   \n",
      "4     536365    84029E       RED WOOLLY HOTTIE WHITE HEART.         6   \n",
      "\n",
      "          InvoiceDate  UnitPrice  CustomerID         Country       Fecha  \\\n",
      "0 2010-12-01 08:26:00       2.55       17850  United Kingdom  2010-12-01   \n",
      "1 2010-12-01 08:26:00       3.39       17850  United Kingdom  2010-12-01   \n",
      "2 2010-12-01 08:26:00       2.75       17850  United Kingdom  2010-12-01   \n",
      "3 2010-12-01 08:26:00       3.39       17850  United Kingdom  2010-12-01   \n",
      "4 2010-12-01 08:26:00       3.39       17850  United Kingdom  2010-12-01   \n",
      "\n",
      "       Hora  TotalAmount AdditionalInfo  \n",
      "0  08:26:00        15.30          Promo  \n",
      "1  08:26:00        20.34          Promo  \n",
      "2  08:26:00        22.00          Promo  \n",
      "3  08:26:00        20.34          Promo  \n",
      "4  08:26:00        20.34          Promo  \n"
     ]
    }
   ],
   "source": [
    "#merge: Combinar dos DataFrames\n",
    "additional_data = pd.DataFrame({\n",
    "    'InvoiceNo': [grouped.index[0], grouped.index[1]],\n",
    "    'AdditionalInfo': ['Promo', 'VIP']\n",
    "})\n",
    "print(\"\\nMerge del DataFrame original con datos adicionales:\")\n",
    "merged_df = pd.merge(df_ecommerce, additional_data, on='InvoiceNo', how='left')\n",
    "print(merged_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primeras filas del DataFrame generado:\n",
      "   Atributo_1  Atributo_2  Atributo_3\n",
      "0   43.708611   61.076999   66.924402\n",
      "1   95.564288   52.570524   23.252997\n",
      "2   75.879455   48.265276   49.420449\n",
      "3   63.879264   45.483445   67.927279\n",
      "4   24.041678   27.822170   11.481921\n",
      "\n",
      "Dimensiones del DataFrame generado: (50, 3)\n"
     ]
    }
   ],
   "source": [
    "# Crear un diccionario con 50 datos que contenga al menos tres atributos continuos\n",
    "np.random.seed(42)  # Para reproducibilidad de resultados\n",
    "data = {\n",
    "    \"Atributo_1\": np.random.uniform(10, 100, 50), \n",
    "    \"Atributo_2\": np.random.normal(50, 15, 50),   \n",
    "    \"Atributo_3\": np.random.exponential(30, 50)   \n",
    "}\n",
    "\n",
    "df_continuos = pd.DataFrame(data)\n",
    "\n",
    "print(\"Primeras filas del DataFrame generado:\")\n",
    "print(df_continuos.head())\n",
    "\n",
    "print(\"\\nDimensiones del DataFrame generado:\", df_continuos.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame generado a partir del diccionario:\n",
      "   Atributo_1  Atributo_2  Atributo_3\n",
      "0           1        10.5       100.1\n",
      "1           2        20.1       200.2\n",
      "2           3        30.2       300.3\n",
      "3           4        40.8       400.4\n",
      "4           5        50.4       500.5\n"
     ]
    }
   ],
   "source": [
    "#Transforme dicho diccionario a un dataFrame de Pandas.\n",
    "data = {\n",
    "    \"Atributo_1\": [1, 2, 3, 4, 5],\n",
    "    \"Atributo_2\": [10.5, 20.1, 30.2, 40.8, 50.4],\n",
    "    \"Atributo_3\": [100.1, 200.2, 300.3, 400.4, 500.5]\n",
    "}\n",
    "\n",
    "df_continuos = pd.DataFrame(data)\n",
    "\n",
    "print(\"DataFrame generado a partir del diccionario:\")\n",
    "print(df_continuos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estadísticas de tendencia central:\n",
      "\n",
      "Media:\n",
      "Atributo_1      3.0\n",
      "Atributo_2     30.4\n",
      "Atributo_3    300.3\n",
      "dtype: float64\n",
      "\n",
      "Mediana:\n",
      "Atributo_1      3.0\n",
      "Atributo_2     30.2\n",
      "Atributo_3    300.3\n",
      "dtype: float64\n",
      "\n",
      "Moda (puede haber más de una):\n",
      "   Atributo_1  Atributo_2  Atributo_3\n",
      "0           1        10.5       100.1\n",
      "1           2        20.1       200.2\n",
      "2           3        30.2       300.3\n",
      "3           4        40.8       400.4\n",
      "4           5        50.4       500.5\n"
     ]
    }
   ],
   "source": [
    "# Obtenga estadísticas descriptivas de tendencia central\n",
    "print(\"Estadísticas de tendencia central:\")\n",
    "#Media\n",
    "media = df_continuos.mean()\n",
    "print(\"\\nMedia:\")\n",
    "print(media)\n",
    "#Mediana\n",
    "mediana = df_continuos.median()\n",
    "print(\"\\nMediana:\")\n",
    "print(mediana)\n",
    "#Moda\n",
    "moda = df_continuos.mode()\n",
    "print(\"\\nModa (puede haber más de una):\")\n",
    "print(moda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estadísticas de dispersión:\n",
      "\n",
      "Rango:\n",
      "Atributo_1      4.0\n",
      "Atributo_2     39.9\n",
      "Atributo_3    400.4\n",
      "dtype: float64\n",
      "\n",
      "Desviación estándar:\n",
      "Atributo_1      1.581139\n",
      "Atributo_2     15.892608\n",
      "Atributo_3    158.271997\n",
      "dtype: float64\n",
      "\n",
      "Varianza:\n",
      "Atributo_1        2.500\n",
      "Atributo_2      252.575\n",
      "Atributo_3    25050.025\n",
      "dtype: float64\n",
      "\n",
      "Percentiles (25%, 50%, 75%):\n",
      "     Atributo_1  Atributo_2  Atributo_3\n",
      "25%         2.0        20.1       200.2\n",
      "50%         3.0        30.2       300.3\n",
      "75%         4.0        40.8       400.4\n"
     ]
    }
   ],
   "source": [
    "# Obtenga estadísticas descriptivas de dispersión\n",
    "print(\"Estadísticas de dispersión:\")\n",
    "\n",
    "# Rango (diferencia entre el valor máximo y mínimo)\n",
    "rango = df_continuos.max() - df_continuos.min()\n",
    "print(\"\\nRango:\")\n",
    "print(rango)\n",
    "\n",
    "desviacion_estandar = df_continuos.std()\n",
    "print(\"\\nDesviación estándar:\")\n",
    "print(desviacion_estandar)\n",
    "\n",
    "# Varianza\n",
    "varianza = df_continuos.var()\n",
    "print(\"\\nVarianza:\")\n",
    "print(varianza)\n",
    "\n",
    "# Percentiles (25%, 50% y 75%)\n",
    "percentiles = df_continuos.describe(percentiles=[0.25, 0.5, 0.75])\n",
    "print(\"\\nPercentiles (25%, 50%, 75%):\")\n",
    "print(percentiles.loc[['25%', '50%', '75%']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo 'ratings_data.csv' cargado correctamente.\n",
      "Codificación detectada para 'books_data.csv': ISO-8859-1\n",
      "Error al cargar 'books_data.csv': read_csv() got an unexpected keyword argument 'error_bad_lines'\n",
      "\n",
      "Primeras filas de 'ratings_data.csv':\n",
      "   Unnamed: 0  User-ID        ISBN  Book-Rating  MeanRating\n",
      "0           0   276725  034545104X            0    2.933333\n",
      "1           1   276726  0155061224            5    2.500000\n",
      "2           2   276727  0446520802            0    4.060345\n",
      "3           3   276729  052165615X            3    3.000000\n",
      "4           4   276729  0521795028            6    6.000000\n",
      "\n",
      "No se pudo cargar 'books_data.csv'.\n"
     ]
    }
   ],
   "source": [
    "#Cargar las bases de datos de nombre \"ratings data.csv\" y \"books data.csv\n",
    "ratings_file = \"ratings_data.csv\"\n",
    "books_file = \"books_data.csv\"\n",
    "\n",
    "try:\n",
    "    ratings_data = pd.read_csv(ratings_file)\n",
    "    print(\"Archivo 'ratings_data.csv' cargado correctamente.\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"No se encontró el archivo '{ratings_file}'. Por favor, verifica la ruta.\")\n",
    "    ratings_data = None\n",
    "except Exception as e:\n",
    "    print(f\"Error al cargar '{ratings_file}': {e}\")\n",
    "    ratings_data = None\n",
    "\n",
    "detected_encoding = None\n",
    "try:\n",
    "    with open(books_file, \"rb\") as file:\n",
    "        result = chardet.detect(file.read(10000))  # Analiza los primeros 10,000 bytes\n",
    "        detected_encoding = result['encoding']\n",
    "        print(f\"Codificación detectada para 'books_data.csv': {detected_encoding}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"No se encontró el archivo '{books_file}'. Por favor, verifica la ruta.\")\n",
    "    books_data = None\n",
    "except Exception as e:\n",
    "    print(f\"Error al analizar la codificación de '{books_file}': {e}\")\n",
    "    books_data = None\n",
    "\n",
    "try:\n",
    "    books_data = pd.read_csv(books_file, encoding='ISO-8859-1', error_bad_lines=False, warn_bad_lines=True)\n",
    "    print(\"Archivo 'books_data.csv' cargado con líneas problemáticas ignoradas.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error al cargar 'books_data.csv': {e}\")\n",
    "\n",
    "if ratings_data is not None:\n",
    "    print(\"\\nPrimeras filas de 'ratings_data.csv':\")\n",
    "    print(ratings_data.head())\n",
    "else:\n",
    "    print(\"\\nNo se pudo cargar 'ratings_data.csv'.\")\n",
    "\n",
    "if books_data is not None:\n",
    "    print(\"\\nPrimeras filas de 'books_data.csv':\")\n",
    "    print(books_data.head())\n",
    "else:\n",
    "    print(\"\\nNo se pudo cargar 'books_data.csv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo 'ratings_data.csv' cargado correctamente.\n",
      "Codificación detectada para 'books_data.csv': ISO-8859-1\n",
      "Archivo 'books_data.csv' cargado correctamente, ignorando líneas problemáticas.\n",
      "\n",
      "Primeras filas de 'ratings_data.csv':\n",
      "   Unnamed: 0  User-ID        ISBN  Book-Rating  MeanRating\n",
      "0           0   276725  034545104X            0    2.933333\n",
      "1           1   276726  0155061224            5    2.500000\n",
      "2           2   276727  0446520802            0    4.060345\n",
      "3           3   276729  052165615X            3    3.000000\n",
      "4           4   276729  0521795028            6    6.000000\n",
      "\n",
      "Primeras filas de 'books_data.csv':\n",
      "  ISBN;\"Book-Title\";\"Book-Author\";\"Year-Of-Publication\";\"Publisher\";\"Image-URL-S\";\"Image-URL-M\";\"Image-URL-L\"\n",
      "0  0195153448;\"Classical Mythology\";\"Mark P. O. M...                                                         \n",
      "1  0002005018;\"Clara Callan\";\"Richard Bruce Wrigh...                                                         \n",
      "2  0060973129;\"Decision in Normandy\";\"Carlo D'Est...                                                         \n",
      "3  0374157065;\"Flu: The Story of the Great Influe...                                                         \n",
      "4  0393045218;\"The Mummies of Urumchi\";\"E. J. W. ...                                                         \n",
      "\n",
      "Dimensiones de 'books_data.csv': (228144, 1)\n"
     ]
    }
   ],
   "source": [
    "ratings_file = \"ratings_data.csv\"\n",
    "books_file = \"books_data.csv\"\n",
    "\n",
    "try:\n",
    "    ratings_data = pd.read_csv(ratings_file)\n",
    "    print(\"Archivo 'ratings_data.csv' cargado correctamente.\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"No se encontró el archivo '{ratings_file}'. Por favor, verifica la ruta.\")\n",
    "    ratings_data = None\n",
    "except Exception as e:\n",
    "    print(f\"Error al cargar '{ratings_file}': {e}\")\n",
    "    ratings_data = None\n",
    "\n",
    "detected_encoding = None\n",
    "try:\n",
    "    with open(books_file, \"rb\") as file:\n",
    "        result = chardet.detect(file.read(10000))  \n",
    "        detected_encoding = result['encoding']\n",
    "        print(f\"Codificación detectada para 'books_data.csv': {detected_encoding}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"No se encontró el archivo '{books_file}'. Por favor, verifica la ruta.\")\n",
    "    books_data = None\n",
    "except Exception as e:\n",
    "    print(f\"Error al analizar la codificación de '{books_file}': {e}\")\n",
    "    books_data = None\n",
    "\n",
    "try:\n",
    "    if detected_encoding:\n",
    "        books_data = pd.read_csv(books_file, encoding=detected_encoding, on_bad_lines='skip')\n",
    "        print(\"Archivo 'books_data.csv' cargado correctamente, ignorando líneas problemáticas.\")\n",
    "    else:\n",
    "        print(\"No se pudo detectar la codificación de 'books_data.csv'.\")\n",
    "        books_data = None\n",
    "except Exception as e:\n",
    "    print(f\"Error al cargar '{books_file}': {e}\")\n",
    "    books_data = None\n",
    "\n",
    "if ratings_data is not None:\n",
    "    print(\"\\nPrimeras filas de 'ratings_data.csv':\")\n",
    "    print(ratings_data.head())\n",
    "else:\n",
    "    print(\"\\nNo se pudo cargar 'ratings_data.csv'.\")\n",
    "\n",
    "if books_data is not None:\n",
    "    print(\"\\nPrimeras filas de 'books_data.csv':\")\n",
    "    print(books_data.head())\n",
    "    print(\"\\nDimensiones de 'books_data.csv':\", books_data.shape)\n",
    "else:\n",
    "    print(\"\\nNo se pudo cargar 'books_data.csv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo 'books_data.csv' cargado correctamente con delimitador ';'.\n",
      "\n",
      "Columnas después de limpiar:\n",
      "Index(['ISBN', 'Book-Title', 'Book-Author', 'Year-Of-Publication', 'Publisher',\n",
      "       'Image-URL-S', 'Image-URL-M', 'Image-URL-L'],\n",
      "      dtype='object')\n",
      "\n",
      "Primeras filas del DataFrame limpio:\n",
      "         ISBN                                        Book-Rating\n",
      "0  0195153448                                Classical Mythology\n",
      "1  0002005018                                       Clara Callan\n",
      "2  0060973129                               Decision in Normandy\n",
      "3  0374157065  Flu: The Story of the Great Influenza Pandemic...\n",
      "4  0393045218                             The Mummies of Urumchi\n",
      "Archivo limpio guardado como 'books_data_cleaned.csv'.\n"
     ]
    }
   ],
   "source": [
    "books_file = \"books_data.csv\"\n",
    "cleaned_books_file = \"books_data_cleaned.csv\"\n",
    "\n",
    "try:\n",
    "    books_data = pd.read_csv(books_file, delimiter=';', encoding='ISO-8859-1', on_bad_lines='skip')\n",
    "    print(\"Archivo 'books_data.csv' cargado correctamente con delimitador ';'.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error al cargar 'books_data.csv': {e}\")\n",
    "    books_data = None\n",
    "\n",
    "if books_data is not None:\n",
    "    books_data.columns = [col.replace('\"', '').strip() for col in books_data.columns]\n",
    "    # Verificar las columnas\n",
    "    print(\"\\nColumnas después de limpiar:\")\n",
    "    print(books_data.columns)\n",
    "    books_data.rename(columns={\"ISBN\": \"ISBN\", \"Book-Title\": \"Book-Rating\"}, inplace=True)\n",
    "\n",
    "    books_data = books_data[[\"ISBN\", \"Book-Rating\"]]\n",
    "\n",
    "    print(\"\\nPrimeras filas del DataFrame limpio:\")\n",
    "    print(books_data.head())\n",
    "\n",
    "    try:\n",
    "        books_data.to_csv(cleaned_books_file, index=False, encoding='utf-8')\n",
    "        print(f\"Archivo limpio guardado como '{cleaned_books_file}'.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error al guardar el archivo limpio: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diagnóstico de números perdidos:\n",
      "Unnamed: 0     0\n",
      "User-ID        0\n",
      "ISBN           0\n",
      "Book-Rating    0\n",
      "MeanRating     0\n",
      "dtype: int64\n",
      "\n",
      "Total de valores faltantes en el dataset: 0\n",
      "\n",
      "Valores imputados con la media en las columnas numéricas:\n",
      "Unnamed: 0     0\n",
      "User-ID        0\n",
      "ISBN           0\n",
      "Book-Rating    0\n",
      "MeanRating     0\n",
      "dtype: int64\n",
      "\n",
      "Valores imputados con la mediana en las columnas numéricas:\n",
      "Unnamed: 0     0\n",
      "User-ID        0\n",
      "ISBN           0\n",
      "Book-Rating    0\n",
      "MeanRating     0\n",
      "dtype: int64\n",
      "\n",
      "Explorando opciones de fillna:\n",
      "Valores faltantes llenados con un valor específico en 'column_name' (ejemplo).\n"
     ]
    }
   ],
   "source": [
    "#Utilizando \"ratings_data.csv\" genere un diagnostico de numeros perdidos. Luego impute los valores de acuerdo a la media y de acuerdo a otro criterio seleccionado por usted. \n",
    "# Explore las opciones de imputacion del metodo fillna() de Pandas.\n",
    "print(\"Diagnóstico de números perdidos:\")\n",
    "missing_summary = ratings_data.isnull().sum()\n",
    "print(missing_summary)\n",
    "\n",
    "total_missing = ratings_data.isnull().sum().sum()\n",
    "print(f\"\\nTotal de valores faltantes en el dataset: {total_missing}\")\n",
    "\n",
    "ratings_data_imputed_mean = ratings_data.copy()\n",
    "for col in ratings_data.columns:\n",
    "    if ratings_data[col].isnull().sum() > 0 and ratings_data[col].dtype in ['float64', 'int64']:\n",
    "        ratings_data_imputed_mean[col] = ratings_data[col].fillna(ratings_data[col].mean())\n",
    "\n",
    "print(\"\\nValores imputados con la media en las columnas numéricas:\")\n",
    "print(ratings_data_imputed_mean.isnull().sum())\n",
    "\n",
    "ratings_data_imputed_median = ratings_data.copy()\n",
    "for col in ratings_data.columns:\n",
    "    if ratings_data[col].isnull().sum() > 0 and ratings_data[col].dtype in ['float64', 'int64']:\n",
    "        ratings_data_imputed_median[col] = ratings_data[col].fillna(ratings_data[col].median())\n",
    "\n",
    "print(\"\\nValores imputados con la mediana en las columnas numéricas:\")\n",
    "print(ratings_data_imputed_median.isnull().sum())\n",
    "\n",
    "print(\"\\nExplorando opciones de fillna:\")\n",
    "ratings_data_filled_custom = ratings_data.copy()\n",
    "ratings_data_filled_custom.fillna(value={'column_name': 'default_value'}, inplace=True)\n",
    "print(\"Valores faltantes llenados con un valor específico en 'column_name' (ejemplo).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bases de datos consolidadas utilizando 'ISBN' como clave (outer join).\n",
      "\n",
      "Primeras filas del DataFrame consolidado:\n",
      "   Unnamed: 0   User-ID         ISBN  Book-Rating_x  MeanRating Book-Rating_y\n",
      "0    371986.0   89192.0   0330299891            0.0         3.0           NaN\n",
      "1    750718.0  181817.0   0330299891            6.0         3.0           NaN\n",
      "2    371987.0   89192.0   0375404120            3.0         1.5           NaN\n",
      "3   1112730.0  266865.0   0375404120            0.0         1.5           NaN\n",
      "4    371988.0   89192.0   0586045007            0.0         0.0           NaN\n",
      "\n",
      "Dimensiones del DataFrame consolidado: (1150989, 6)\n"
     ]
    }
   ],
   "source": [
    "# Utilizando la columna ISBN de cada base de datos consolidelas en una sola base de datos con todos los atributos de \"books data.csv\"\n",
    "if ratings_data is not None and books_data_cleaned is not None:\n",
    "    if 'ISBN' in ratings_data.columns and 'ISBN' in books_data_cleaned.columns:\n",
    "        consolidated_data = pd.merge(ratings_data, books_data_cleaned, on='ISBN', how='outer')\n",
    "        print(\"Bases de datos consolidadas utilizando 'ISBN' como clave (outer join).\")\n",
    "\n",
    "        print(\"\\nPrimeras filas del DataFrame consolidado:\")\n",
    "        print(consolidated_data.head())\n",
    "\n",
    "        print(\"\\nDimensiones del DataFrame consolidado:\", consolidated_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo consolidado exportado exitosamente como 'consolidated_data.csv'.\n"
     ]
    }
   ],
   "source": [
    "#Exporte la base de datos consolidada\n",
    "if 'consolidated_data' in locals() and consolidated_data is not None:\n",
    "    try:\n",
    "        consolidated_file = \"consolidated_data.csv\"\n",
    "        consolidated_data.to_csv(consolidated_file, index=False, encoding=\"utf-8\")\n",
    "        print(f\"Archivo consolidado exportado exitosamente como '{consolidated_file}'.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error al exportar el archivo consolidado: {e}\")\n",
    "else:\n",
    "    print(\"El DataFrame consolidado no está disponible para exportar.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
