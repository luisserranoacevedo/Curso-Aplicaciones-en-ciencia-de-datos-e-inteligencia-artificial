{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.impute import SimpleImputer\n",
    "from scipy.stats import shapiro\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pickle\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, roc_auc_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Las instrucciones dicen que debe ser una boleana para la muestra, pero es más eficiente pedir directamente el número y trabajarla como boleana dentro de la función. Además que sirve para detectar si el número ingresado es más grande que los datos\n",
    "\n",
    "def cargar_datos(ruta, n_muestra=None, variables =None, separador= None, codificacion=None): \n",
    "    try:\n",
    "        df=pd.read_csv(ruta, sep=separador, usecols= variables, encoding=codificacion)\n",
    "        if n_muestra:\n",
    "            if n_muestra > len(df):\n",
    "                print(f\"El número proporcionado: {n_muestra} es mayor que la cantidad de datos: {len(df)}\")\n",
    "            else:\n",
    "                df=df.sample(n=n_muestra, random_state=25)\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"No se pudo importar el dataframe {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "#diagnóstico de los datos. \n",
    "\n",
    "def descriptivos(df, columnas=None, faltantes=None, media=None, mediana=None, desv_estandar=None, minimo=None, maximo=None):\n",
    "    #Por si columnas está vacío, cargamos dataframe completo, pero seleccionamos las variables numéricas para ejecutar el diagnóstico.\n",
    "    if columnas is None:\n",
    "        columnas=df.select_dtypes(include=\"number\").columns\n",
    "    #Se intentó con listas, pero el diccionario resultó más manejable para la conversión en dataframe para presentar al final de la función.\n",
    "    diagnostico={}\n",
    "\n",
    "    for columna in columnas:\n",
    "        #Hacemos un diccionario para guardar los números calculados\n",
    "        medidas={}\n",
    "        \n",
    "        if faltantes:\n",
    "            medidas['faltantes']=df[columna].isnull().sum()\n",
    "        if media:\n",
    "            medidas['media']=df[columna].mean()\n",
    "        if mediana:\n",
    "            medidas['mediana']=df[columna].median()\n",
    "        if desv_estandar:\n",
    "            medidas['desv.estandar']=df[columna].std()\n",
    "        if minimo:\n",
    "            medidas['mínimo']=df[columna].min()\n",
    "        if maximo:\n",
    "            medidas['máximo']=df[columna].max()\n",
    "\n",
    "        #Poblamos el diccionario con los números del diagnóstico y las diferentes columnas que pasan por el ciclo\n",
    "        diagnostico[columna]=medidas\n",
    "\n",
    "    diagnostico=pd.DataFrame(diagnostico)\n",
    "    return diagnostico\n",
    "\n",
    "#Imputación de datos\n",
    "def imputar_datos(df, descriptores, estrategias):\n",
    "    #Hacemos copia profunda para evitar modificaciones no previstas\n",
    "    df_imputado=df.copy(deep=True)\n",
    "    #nos aseguramos que las listas de descriptores y estrategias tengan el mismo largo.\n",
    "    if len(descriptores) != len(estrategias):\n",
    "        raise ValueError(\"Las listas de descriptores y estrategias deben ser del mismo largo\")\n",
    "    for i, columna in enumerate(descriptores):\n",
    "        if columna in df_imputado.columns:\n",
    "            if estrategias[i] == 'media':\n",
    "                imputacion=df_imputado[columna].mean()\n",
    "            elif estrategias[i] =='mediana':\n",
    "                imputacion=df_imputado[columna].median()\n",
    "            else:\n",
    "                print(\"Estrategia no válida\")\n",
    "            df_imputado[columna]=df_imputado[columna].fillna(imputacion)\n",
    "\n",
    "    return df_imputado\n",
    "\n",
    "#Graficadora.\n",
    "\n",
    "def graficadora(df, variable_x, variable_y, categorica=None):\n",
    "    plt.figure(figsize= (10, 5))\n",
    "    sns.scatterplot(data=df, x=variable_x, y=variable_y)\n",
    "    plt.title(f\"Gráfico dispersión relación entre {variable_x} y {variable_y}\")\n",
    "    plt.xlabel(variable_x)\n",
    "    plt.ylabel(variable_y)\n",
    "    plt.savefig(f\"Dispersión {variable_x}-{variable_y}.png\")\n",
    "\n",
    "    if categorica:\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        sns.boxplot(data=df, x=categorica, y=variable_y)\n",
    "        plt.title(f\"Boxplot {categorica} y {variable_y}\")\n",
    "        plt.xlabel(categorica)\n",
    "        plt.ylabel(variable_y)\n",
    "        plt.savefig(f\"boxplot {categorica}-{variable_y}.png\")\n",
    "\n",
    "        #Estandarización de datos.\n",
    "\n",
    "def estandarizadora(df, descriptores, estrategias):\n",
    "    #podemos reciclar desde las imputaciones\n",
    "    df_estandarizado =df.copy(deep=True)\n",
    "    #nos aseguramos que las listas de descriptores y estrategias tengan el mismo largo, también reciclado.\n",
    "    if len(descriptores) != len(estrategias):\n",
    "        raise ValueError(\"Las listas de descriptores y estrategias deben ser del mismo largo\")\n",
    "    \n",
    "    for i, columna in enumerate(descriptores):\n",
    "        if columna in df_estandarizado.columns:\n",
    "            estrategia=estrategias[i]\n",
    "            if estrategia == \"z\":\n",
    "                scaler=StandardScaler()\n",
    "                df_estandarizado[columna]=scaler.fit_transform(df_estandarizado[[columna]])\n",
    "            elif estrategia == \"minmax\":\n",
    "                scaler=MinMaxScaler()\n",
    "                df_estandarizado[columna]=scaler.fit_transform(df_estandarizado[[columna]])\n",
    "            else:\n",
    "                print(\"Debe ser estandarización Z o tipo Minmax\")\n",
    "        else:\n",
    "            print(\"Columna no encontrada en el dataframe\")\n",
    "    return df_estandarizado\n",
    "\n",
    "#Creación de train y test.\n",
    "\n",
    "def generadora_set(df, target, test_size=0.2, random_state=20):\n",
    "    X=df.drop(columns=[target])\n",
    "    y=df[target]\n",
    "    X_train, X_test, y_train, y_test=train_test_split(X, y, test_size=test_size, random_state=random_state, stratify=y)\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "\n",
    "#Función para entrenar y guardar un modelo de clasificación.\n",
    "\n",
    "def clasificador(tipo_clasificador, ruta_salida, datos_entrenar):\n",
    "    X_train, y_train= datos_entrenar\n",
    "\n",
    "    if tipo_clasificador ==\"GaussianNB\":\n",
    "        modelo= GaussianNB()\n",
    "    elif tipo_clasificador==\"LogisticRegression\":\n",
    "        modelo=LogisticRegression(max_iter=2000)\n",
    "    else:\n",
    "        print(\"Clasificador incorrecto\")\n",
    "    modelo.fit(X_train, y_train)\n",
    "\n",
    "    #Guardamos el modelo para poderlo usar en la siguiente pregunta. usamos with.\n",
    "\n",
    "    with open(ruta_salida, \"wb\") as ruta_archivo:\n",
    "        pickle.dump(modelo, ruta_archivo)\n",
    "\n",
    "        print(f\"{tipo_clasificador} guardado en {ruta_salida}\")\n",
    "\n",
    "\n",
    "#Función para evaluar los modelos\n",
    "\n",
    "def evaluar_modelo(modelo, X_test, y_test, metrica):\n",
    "    predicciones = modelo.predict(X_test)\n",
    "\n",
    "    #Métricas\n",
    "    accuracy = accuracy_score(y_test, predicciones)\n",
    "    f1_macro = f1_score(y_test, predicciones, average=\"macro\")\n",
    "    f1_weighted = f1_score(y_test, predicciones, average=\"weighted\")\n",
    "    matriz_confusion = confusion_matrix(y_test, predicciones)\n",
    "    reporte_clasificacion = classification_report(y_test, predicciones)\n",
    "\n",
    "    \n",
    "    \n",
    "    if metrica==\"accuracy\":\n",
    "        print(\"Accuracy:\", accuracy)\n",
    "    elif metrica ==\"f1_macro\":\n",
    "        print(\"F1 Score (macro):\", f1_macro)\n",
    "    elif metrica ==\"f1_weighted\":\n",
    "        print(\"F1 Score (weighted):\", f1_weighted)\n",
    "    elif metrica==\"matriz_confusion\":\n",
    "        print(\"Matriz de Confusión:\\n\", matriz_confusion)\n",
    "    elif metrica==\"reporte_clasificacion\":\n",
    "        print(\"Reporte de Clasificación:\\n\", reporte_clasificacion)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=cargar_datos(\"Gaia_NaN.csv\", separador=\";\") # Instrucciones 3.1.2\n",
    "\n",
    "#borramos id de la base de datos.\n",
    "\n",
    "df=df.drop(\"ID\", axis=1)\n",
    "\n",
    "#Vamos a eliminar las filas que tengan NA en Class.\n",
    "df=df.dropna(subset=\"Class\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Función de diagnóstico # Instrucciones 3.1.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def descriptivos(df, columnas=None, faltantes=None, media=None, mediana=None, desv_estandar=None, minimo=None, maximo=None):\n",
    "    #Por si columnas está vacío, cargamos dataframe completo, pero seleccionamos las variables numéricas para ejecutar el diagnóstico.\n",
    "    if columnas is None:\n",
    "        columnas=df.select_dtypes(include=\"number\").columns\n",
    "    #Se intentó con listas, pero el diccionario resultó más manejable para la conversión en dataframe para presentar al final de la función.\n",
    "    diagnostico={}\n",
    "\n",
    "    for columna in columnas:\n",
    "        #Hacemos un diccionario para guardar los números calculados\n",
    "        medidas={}\n",
    "        \n",
    "        if faltantes:\n",
    "            medidas['faltantes']=df[columna].isnull().sum()\n",
    "        if media:\n",
    "            medidas['media']=df[columna].mean()\n",
    "        if mediana:\n",
    "            medidas['mediana']=df[columna].median()\n",
    "        if desv_estandar:\n",
    "            medidas['desv.estandar']=df[columna].std()\n",
    "        if minimo:\n",
    "            medidas['mínimo']=df[columna].min()\n",
    "        if maximo:\n",
    "            medidas['máximo']=df[columna].max()\n",
    "\n",
    "        #Poblamos el diccionario con los números del diagnóstico y las diferentes columnas que pasan por el ciclo\n",
    "        diagnostico[columna]=medidas\n",
    "\n",
    "    diagnostico=pd.DataFrame(diagnostico)\n",
    "    return diagnostico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prueba_funcion=descriptivos(df, media=True, mediana=True, faltantes=True, desv_estandar=True, minimo=True, maximo=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prueba_funcion.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prueba de normalidad. Forma de identificar si es mejor imputar por la media o la mediana dependiendo de la normalidad de los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalidad_Shapiro(df, columnas=None):\n",
    "    if columnas is None:\n",
    "        columnas=df.select_dtypes(include=\"number\").columns.tolist()\n",
    "\n",
    "    resultados = []\n",
    "\n",
    "    for columna in columnas:\n",
    "        try:\n",
    "            stat, p=shapiro(df[columna].dropna())\n",
    "            resultados.append({\n",
    "                \"columna\": columna, \"p_valor\": p, \"normalidad\": \"Normal\" if p >0.05 else \"No normal\"\n",
    "            })\n",
    "        except Exception as e:\n",
    "            resultados.append({\"columna\": columna, \"error\": str(e)})\n",
    "        \n",
    "    resultados= pd.DataFrame(resultados)\n",
    "    return resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalidad=normalidad_Shapiro(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalidad[normalidad['normalidad']==\"Normal\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imputaciones # Instrucciones 3.1.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptores_i = [\"N\", \"Amplitude\", \"Rcs\", \"Meanvariance\", \"Autocor_length\", \"SlottedA_length\", \"Con\", \"SmallKurtosis\", \"Std\", \"Skew\", \"MaxSlope\", \"MedianAbsDev\", \"MedianBRP\", \"PairSlopeTrend\", \"FluxPercentileRatioMid20\", \"FluxPercentileRatioMid35\", \"FluxPercentileRatioMid50\", \"FluxPercentileRatioMid65\", \"FluxPercentileRatioMid80\", \"PercentDifferenceFluxPercentile\", \"PercentAmplitude\", \"LinearTrend\", \"Eta_e\", \"Mean\", \"Q31\", \"AndersonDarling\", \"PeriodLS\", \"Period_fit\", \"Psi_CS\", \"Psi_eta\", \"Freq1_harmonics_amplitude_0\", \"Freq1_harmonics_amplitude_1\", \"Freq1_harmonics_amplitude_2\", \"Freq1_harmonics_amplitude_3\", \"Freq2_harmonics_amplitude_0\", \"Freq2_harmonics_amplitude_1\", \"Freq2_harmonics_amplitude_2\", \"Freq2_harmonics_amplitude_3\", \"Freq3_harmonics_amplitude_0\", \"Freq3_harmonics_amplitude_1\", \"Freq3_harmonics_amplitude_2\", \"Freq3_harmonics_amplitude_3\", \"Freq1_harmonics_rel_phase_0\", \"Freq1_harmonics_rel_phase_1\", \"Freq1_harmonics_rel_phase_2\", \"Freq1_harmonics_rel_phase_3\", \"Freq2_harmonics_rel_phase_0\", \"Freq2_harmonics_rel_phase_1\", \"Freq2_harmonics_rel_phase_2\", \"Freq2_harmonics_rel_phase_3\", \"Freq3_harmonics_rel_phase_0\", \"Freq3_harmonics_rel_phase_1\", \"Freq3_harmonics_rel_phase_2\", \"Freq3_harmonics_rel_phase_3\", \"\"]\n",
    "\n",
    "estrategias_i=[\"mediana\", \"mediana\", \"mediana\", \"mediana\", \"mediana\", \"mediana\", \"mediana\", \"mediana\", \"mediana\", \"mediana\", \"mediana\", \"mediana\", \"mediana\", \"mediana\", \"mediana\", \"media\", \"mediana\", \"mediana\", \"mediana\", \"mediana\", \"mediana\", \"mediana\", \"mediana\", \"media\", \"mediana\", \"mediana\", \"mediana\", \"mediana\", \"mediana\", \"mediana\", \"mediana\", \"media\", \"mediana\", \"mediana\", \"mediana\", \"mediana\", \"mediana\", \"mediana\", \"mediana\", \"mediana\", \"mediana\", \"mediana\", \"mediana\", \"mediana\", \"mediana\", \"mediana\", \"mediana\", \"mediana\", \"mediana\", \"mediana\", \"mediana\", \"mediana\", \"mediana\", \"mediana\", \"mediana\"]\n",
    "\n",
    "\n",
    "#print(pd.DataFrame({\"columna a\": descriptores_i, \"columna 2\": estrategias_i}).head(25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imputar_datos(df, descriptores, estrategias):\n",
    "    #Hacemos copia profunda para evitar modificaciones no previstas\n",
    "    df_imputado=df.copy(deep=True)\n",
    "    #nos aseguramos que las listas de descriptores y estrategias tengan el mismo largo.\n",
    "    if len(descriptores) != len(estrategias):\n",
    "        raise ValueError(\"Las listas de descriptores y estrategias deben ser del mismo largo\")\n",
    "    for i, columna in enumerate(descriptores):\n",
    "        if columna in df_imputado.columns:\n",
    "            if estrategias[i] == 'media':\n",
    "                imputacion=df_imputado[columna].mean()\n",
    "            elif estrategias[i] =='mediana':\n",
    "                imputacion=df_imputado[columna].median()\n",
    "            else:\n",
    "                print(\"Estrategia no válida\")\n",
    "            df_imputado[columna]=df_imputado[columna].fillna(imputacion)\n",
    "\n",
    "    return df_imputado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputados=imputar_datos(df, descriptores_i, estrategias_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputaciones=descriptivos(imputados, media=True, mediana=True, faltantes=True, desv_estandar=True, minimo=True, maximo=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "prueba imputaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputaciones.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "función graficadora # Instrucciones 3.1.5 y 3.1.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graficadora(df, variable_x, variable_y, categorica=None):\n",
    "    plt.figure(figsize= (10, 5))\n",
    "    sns.scatterplot(data=df, x=variable_x, y=variable_y)\n",
    "    plt.title(f\"Gráfico dispersión relación entre {variable_x} y {variable_y}\")\n",
    "    plt.xlabel(variable_x)\n",
    "    plt.ylabel(variable_y)\n",
    "    plt.savefig(f\"Dispersión {variable_x}-{variable_y}.png\")\n",
    "\n",
    "    if categorica:\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        sns.boxplot(data=df, x=categorica, y=variable_y)\n",
    "        plt.title(f\"Boxplot {categorica} y {variable_y}\")\n",
    "        plt.xlabel(categorica)\n",
    "        plt.ylabel(variable_y)\n",
    "        plt.savefig(f\"boxplot {categorica}-{variable_y}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graficadora(imputados, variable_x=\"N\", variable_y= \"Amplitude\", categorica=\"Class\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "prueba atipicos. Usamos esto para analizar la presencia de datos atípicos y juzgar que operación es la más conveniente antes de estandarizar. particularmente relevante, pues si hay muchos atípicos la estandarización no es capaz de manejar este problema. incluiremos esto en la clase final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contar_atipicos(df, columna, metodo=\"iqr\", umbral=1.5):\n",
    "\n",
    "    valores = df[columna].dropna()  \n",
    "    if metodo == \"iqr\":\n",
    "        #esto es IQR\n",
    "        Q1 = np.percentile(valores, 25) \n",
    "        Q3 = np.percentile(valores, 75) \n",
    "        IQR = Q3 - Q1\n",
    "        limite_inferior = Q1 - umbral * IQR\n",
    "        limite_superior = Q3 + umbral * IQR\n",
    "        \n",
    "        atipicos_inferior= valores[valores< limite_inferior].count()\n",
    "        atipicos_superior = valores[valores> limite_superior].count()\n",
    "        atipicos_totales = atipicos_inferior+atipicos_superior\n",
    "    elif metodo == \"zscore\":\n",
    "        #probamos con z\n",
    "        z_scores = (valores - valores.mean()) / valores.std()\n",
    "        atipicos = valores[np.abs(z_scores) > umbral]\n",
    "    else:\n",
    "        raise ValueError(\"Método no válido. Usa 'iqr' o 'zscore'.\")\n",
    "    \n",
    "    return {\"Total atípicos\": atipicos_totales, \"Atípicos por debajo\": atipicos_inferior, \"Atípicos por encima\": atipicos_superior}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "estandarización # Instrucciones 3.1.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estandarizadora(df, descriptores, estrategias):\n",
    "    #podemos reciclar desde las imputaciones\n",
    "    df_estandarizado =df.copy(deep=True)\n",
    "    #nos aseguramos que las listas de descriptores y estrategias tengan el mismo largo, también reciclado.\n",
    "    if len(descriptores) != len(estrategias):\n",
    "        raise ValueError(\"Las listas de descriptores y estrategias deben ser del mismo largo\")\n",
    "    \n",
    "    for i, columna in enumerate(descriptores):\n",
    "        if columna in df_estandarizado.columns:\n",
    "            estrategia=estrategias[i]\n",
    "            if estrategia == \"z\":\n",
    "                scaler=StandardScaler()\n",
    "                df_estandarizado[columna]=scaler.fit_transform(df_estandarizado[[columna]])\n",
    "            elif estrategia == \"minmax\":\n",
    "                scaler=MinMaxScaler()\n",
    "                df_estandarizado[columna]=scaler.fit_transform(df_estandarizado[[columna]])\n",
    "            else:\n",
    "                print(\"Debe ser estandarización Z o tipo Minmax\")\n",
    "        else:\n",
    "            print(\"Columna no encontrada en el dataframe\")\n",
    "    return df_estandarizado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estandarizada=estandarizadora(imputados, [\"N\", \"Amplitude\"], [\"z\", \"z\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "generación de train y test # Instrucciones 3.1.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generadora_set(df, target, test_size=0.2, random_state=20):\n",
    "    X=df.drop(columns=[target])\n",
    "    y=df[target]\n",
    "    X_train, X_test, y_train, y_test=train_test_split(X, y, test_size=test_size, random_state=random_state, stratify=y)\n",
    "\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test=generadora_set(estandarizada, \"Class\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "clase # Instrucciones 3.1.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Preprocesamiento:\n",
    "    def __init__(self):\n",
    "        self.df = None\n",
    "        self.label_encoder = None\n",
    "\n",
    "    def cargar_datos(self, ruta, n_muestra=None, variables=None, separador=\",\", codificacion=\"utf-8\"):\n",
    "        try:\n",
    "            self.df = pd.read_csv(ruta, sep=separador, usecols=variables, encoding=codificacion)\n",
    "            \n",
    "            # Eliminar columna 'ID'\n",
    "            if 'ID' in self.df.columns:\n",
    "                self.df.drop(columns=['ID'], inplace=True)\n",
    "                print(\"Columna 'ID' eliminada.\")\n",
    "            \n",
    "            \n",
    "            if n_muestra:\n",
    "                if n_muestra > len(self.df):\n",
    "                    print(f\"El número proporcionado: {n_muestra} es mayor que la cantidad de datos: {len(self.df)}\")\n",
    "                else:\n",
    "                    self.df = self.df.sample(n=n_muestra, random_state=25)\n",
    "            \n",
    "            print(\"Datos cargados exitosamente.\")\n",
    "            return self.df\n",
    "        except Exception as e:\n",
    "            print(f\"No se pudo importar el dataframe: {e}\")\n",
    "            return None\n",
    "\n",
    "    def resetear_datos(self):\n",
    "        #Por problemas en la ejecución repetida,  mejor resetear el asunto\n",
    "        self.df = None\n",
    "        print(\"Datos reseteados. Ahora puedes cargar nuevos datos.\")\n",
    "\n",
    "    def verificar_df(self):\n",
    "        \n",
    "        if self.df is None:\n",
    "            raise ValueError(\"No se ha cargado ningún DataFrame. Usa el método `cargar_datos` primero.\")\n",
    "\n",
    "    def descriptivos(self, columnas=None, faltantes=None, media=None, mediana=None, desv_estandar=None, minimo=None, maximo=None):\n",
    "        self.verificar_df()  # Verifica si hay un DataFrame cargado\n",
    "        if columnas is None:\n",
    "            columnas = self.df.select_dtypes(include=\"number\").columns\n",
    "        \n",
    "        diagnostico = {}\n",
    "        for columna in columnas:\n",
    "            medidas = {}\n",
    "            if faltantes:\n",
    "                medidas['faltantes'] = self.df[columna].isnull().sum()\n",
    "            if media:\n",
    "                medidas['media'] = self.df[columna].mean()\n",
    "            if mediana:\n",
    "                medidas['mediana'] = self.df[columna].median()\n",
    "            if desv_estandar:\n",
    "                medidas['desv.estandar'] = self.df[columna].std()\n",
    "            if minimo:\n",
    "                medidas['mínimo'] = self.df[columna].min()\n",
    "            if maximo:\n",
    "                medidas['máximo'] = self.df[columna].max()\n",
    "            \n",
    "            diagnostico[columna] = medidas\n",
    "        \n",
    "        diagnostico = pd.DataFrame(diagnostico)\n",
    "        return diagnostico\n",
    "\n",
    "    def imputar_datos(self, descriptores, estrategias):\n",
    "        df_imputado = self.df.copy(deep=True)\n",
    "        if len(descriptores) != len(estrategias):\n",
    "            raise ValueError(\"Las listas de descriptores y estrategias deben ser del mismo largo\")\n",
    "\n",
    "        for i, columna in enumerate(descriptores):\n",
    "            if columna in df_imputado.columns:\n",
    "                if pd.api.types.is_numeric_dtype(df_imputado[columna]):\n",
    "                    # Imputación numérica\n",
    "                    if estrategias[i] == 'media':\n",
    "                        imputacion = df_imputado[columna].mean()\n",
    "                    elif estrategias[i] == 'mediana':\n",
    "                        imputacion = df_imputado[columna].median()\n",
    "                    else:\n",
    "                        print(f\"Estrategia '{estrategias[i]}' no válida para la columna numérica '{columna}'\")\n",
    "                    df_imputado[columna] = df_imputado[columna].fillna(imputacion)\n",
    "                else:\n",
    "                    # Imputación categórica o no numérica\n",
    "                    if estrategias[i] == 'moda':\n",
    "                        imputacion = df_imputado[columna].mode()[0]\n",
    "                        df_imputado[columna] = df_imputado[columna].fillna(imputacion)\n",
    "                    else:\n",
    "                        print(f\"Estrategia '{estrategias[i]}' no válida para la columna categórica '{columna}'\")\n",
    "            else:\n",
    "                print(f\"Columna '{columna}' no encontrada en el DataFrame.\")\n",
    "\n",
    "        self.df = df_imputado\n",
    "        return df_imputado\n",
    "\n",
    "    def graficadora(self, variable_x, variable_y, categorica=None):\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        sns.scatterplot(data=self.df, x=variable_x, y=variable_y)\n",
    "        plt.title(f\"Gráfico dispersión relación entre {variable_x} y {variable_y}\")\n",
    "        plt.xlabel(variable_x)\n",
    "        plt.ylabel(variable_y)\n",
    "        plt.savefig(f\"Dispersión {variable_x}-{variable_y}.png\")\n",
    "\n",
    "        if categorica:\n",
    "            plt.figure(figsize=(10, 5))\n",
    "            sns.boxplot(data=self.df, x=categorica, y=variable_y)\n",
    "            plt.title(f\"Boxplot {categorica} y {variable_y}\")\n",
    "            plt.xlabel(categorica)\n",
    "            plt.ylabel(variable_y)\n",
    "            plt.savefig(f\"boxplot {categorica}-{variable_y}.png\")\n",
    "\n",
    "    \n",
    "    #Hay muchos atípicos en la base de datos cuya estandarización con Z o minmax no elimina el problema de lpeso de las colas. Incorporamos un método para eliminar columnas que tengan más de un X % de atípicos. Usaremos el 5 % como base de trabajo\n",
    "    def eliminar_atipicas(self, umbral=None):\n",
    "        self.verificar_df()\n",
    "        columnas_eliminadas=[]\n",
    "        columnas_numericas = self.df.select_dtypes(include=\"number\").columns\n",
    "        self.umbral=umbral\n",
    "        \n",
    "        for columna in columnas_numericas:\n",
    "            q1=self.df[columna].quantile(0.25)\n",
    "            q3=self.df[columna].quantile(0.75)\n",
    "            iqr= q3-q1\n",
    "            datos_atipicos= self.df[(self.df[columna] < q1 - 1.5 * iqr) | (self.df[columna] > q3 + 1.5* iqr)]\n",
    "            porcentaje_atipicos= len(datos_atipicos) / len(self.df)\n",
    "\n",
    "            if porcentaje_atipicos > umbral:\n",
    "                columnas_eliminadas.append(columna)\n",
    "        self.df=self.df.drop(columns=columnas_eliminadas)\n",
    "        return self.df\n",
    "    \n",
    "    def estandarizadora(self, descriptores, estrategias):\n",
    "        df_estandarizado = self.df.copy(deep=True)\n",
    "        if len(descriptores) != len(estrategias):\n",
    "            raise ValueError(\"Las listas de descriptores y estrategias deben ser del mismo largo\")\n",
    "        \n",
    "        for i, columna in enumerate(descriptores):\n",
    "            if columna in df_estandarizado.columns:\n",
    "                estrategia = estrategias[i]\n",
    "                if estrategia == \"z\":\n",
    "                    scaler = StandardScaler()\n",
    "                    df_estandarizado[columna] = scaler.fit_transform(df_estandarizado[[columna]])\n",
    "                elif estrategia == \"minmax\":\n",
    "                    scaler = MinMaxScaler()\n",
    "                    df_estandarizado[columna] = scaler.fit_transform(df_estandarizado[[columna]])\n",
    "                else:\n",
    "                    print(\"Debe ser estandarización Z o tipo Minmax\")\n",
    "            else:\n",
    "                print(\"Columna no encontrada en el dataframe\")\n",
    "        \n",
    "        self.df = df_estandarizado\n",
    "        return df_estandarizado\n",
    "\n",
    "    def generadora_set(self, target, test_size=0.2, random_state=20):\n",
    "        X = self.df.drop(columns=[target])\n",
    "        y = self.df[target]\n",
    "        \n",
    "        #Transformamos la variable objetivo antes de separar los datos. Esto como elemento para introducirla al modelo. podría incluri un if para controlar los tipos, pero por ahora esto funciona bien.\n",
    "        self.label_encoder=LabelEncoder()\n",
    "        y=self.label_encoder.fit_transform(y)\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state, stratify=y)\n",
    "        return X_train, X_test, y_train, y_test\n",
    "\n",
    "    def ejecutar_preprocesamiento(self, ruta, n_muestra=None, variables=None, separador=None, codificacion=None, \n",
    "                          descriptores=None, estrategias_imputacion=None, umbral=None, estandarizacion=None, \n",
    "                          graficos=None, target=None, test_size=0.2, random_state=20):\n",
    "        # Cargar datos\n",
    "        self.cargar_datos(ruta, n_muestra, variables, separador, codificacion)\n",
    "        print(\"Datos cargados.\")\n",
    "\n",
    "        # Descriptivos\n",
    "        descriptivo = self.descriptivos(faltantes=True, media=True, mediana=True, desv_estandar=True, minimo=True, maximo=True)\n",
    "        print(\"Descriptivos calculados.\")\n",
    "        print(descriptivo)\n",
    "\n",
    "        # Imputación de datos\n",
    "        if descriptores and estrategias_imputacion:\n",
    "            self.imputar_datos(descriptores, estrategias_imputacion)\n",
    "            print(\"Imputación realizada.\")\n",
    "\n",
    "        #eliminacion atipicos\n",
    "        self.eliminar_atipicas(umbral=umbral)\n",
    "                \n",
    "        \n",
    "        # Estandarización\n",
    "        if descriptores and estandarizacion:\n",
    "            self.estandarizadora(descriptores, estandarizacion)\n",
    "            print(\"Estandarización realizada.\")\n",
    "\n",
    "        # Graficadora\n",
    "        if graficos:\n",
    "            for grafico in graficos:\n",
    "                self.graficadora(**grafico)\n",
    "            print(\"Gráficos generados.\")\n",
    "\n",
    "        # Generación de datos de entrenamiento/test\n",
    "        if target:\n",
    "            X_train, X_test, y_train, y_test = self.generadora_set(target, test_size, random_state)\n",
    "            print(\"Sets generados.\")\n",
    "            return X_train, X_test, y_train, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "procesador=Preprocesamiento()\n",
    "descriptores_i = [\"N\", \"Amplitude\", \"Rcs\", \"Meanvariance\", \"Autocor_length\", \"SlottedA_length\", \"Con\", \"SmallKurtosis\", \"Std\", \"Skew\", \"MaxSlope\", \"MedianAbsDev\", \"MedianBRP\", \"PairSlopeTrend\", \"FluxPercentileRatioMid20\", \"FluxPercentileRatioMid35\", \"FluxPercentileRatioMid50\", \"FluxPercentileRatioMid65\", \"FluxPercentileRatioMid80\", \"PercentDifferenceFluxPercentile\", \"PercentAmplitude\", \"LinearTrend\", \"Eta_e\", \"Mean\", \"Q31\", \"AndersonDarling\", \"PeriodLS\", \"Period_fit\", \"Psi_CS\", \"Psi_eta\", \"Freq1_harmonics_amplitude_0\", \"Freq1_harmonics_amplitude_1\", \"Freq1_harmonics_amplitude_2\", \"Freq1_harmonics_amplitude_3\", \"Freq2_harmonics_amplitude_0\", \"Freq2_harmonics_amplitude_1\", \"Freq2_harmonics_amplitude_2\", \"Freq2_harmonics_amplitude_3\", \"Freq3_harmonics_amplitude_0\", \"Freq3_harmonics_amplitude_1\", \"Freq3_harmonics_amplitude_2\", \"Freq3_harmonics_amplitude_3\", \"Freq1_harmonics_rel_phase_0\", \"Freq1_harmonics_rel_phase_1\", \"Freq1_harmonics_rel_phase_2\", \"Freq1_harmonics_rel_phase_3\", \"Freq2_harmonics_rel_phase_0\", \"Freq2_harmonics_rel_phase_1\", \"Freq2_harmonics_rel_phase_2\", \"Freq2_harmonics_rel_phase_3\", \"Freq3_harmonics_rel_phase_0\", \"Freq3_harmonics_rel_phase_1\", \"Freq3_harmonics_rel_phase_2\", \"Freq3_harmonics_rel_phase_3\", \"\", \"Class\"]\n",
    "\n",
    "estrategias_i=[\"mediana\", \"mediana\", \"mediana\", \"mediana\", \"mediana\", \"mediana\", \"mediana\", \"mediana\", \"mediana\", \"mediana\", \"mediana\", \"mediana\", \"mediana\", \"mediana\", \"mediana\", \"media\", \"mediana\", \"mediana\", \"mediana\", \"mediana\", \"mediana\", \"mediana\", \"mediana\", \"media\", \"mediana\", \"mediana\", \"mediana\", \"mediana\", \"mediana\", \"mediana\", \"mediana\", \"media\", \"mediana\", \"mediana\", \"mediana\", \"mediana\", \"mediana\", \"mediana\", \"mediana\", \"mediana\", \"mediana\", \"mediana\", \"mediana\", \"mediana\", \"mediana\", \"mediana\", \"mediana\", \"mediana\", \"mediana\", \"mediana\", \"mediana\", \"mediana\", \"mediana\", \"mediana\", \"mediana\", \"moda\"]\n",
    "\n",
    "\n",
    "#Función para ejecutar los métodos. En este caso usamos lo necesario para producir los insumos para el entrenamiento y prueba de los modelos\n",
    "X_train, X_test, y_train, y_test=procesador.ejecutar_preprocesamiento(ruta=\"Gaia_NaN.csv\", separador=\";\", descriptores=descriptores_i, estrategias_imputacion=estrategias_i, umbral= 0.05, test_size=0.2, random_state=30, target=\"Class\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "modelo de clasificación GaussianNB # Instrucciones 3.2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clasificador(tipo_clasificador=\"GaussianNB\", ruta_salida=\"modelo_g.pkl\", datos_entrenar=(X_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"modelo_g.pkl\", \"rb\") as modelo_g:\n",
    "    modelo_ga=pickle.load(modelo_g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluar_modelo(modelo_ga, X_test, y_test, metrica=\"f1_macro\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Según la documentación, modificar los priors sirve para asignar manualmente un peso cuando las clases son desbalanceadas. En este caso probamos asignando la misma probabilidad a todas las clases. no obstante, este modelo funciona peor que el entrenado por defecto, con un 0.30 en el f1_macro frent a un 0.37 del otro modelo.\n",
    "\n",
    "priors = [1/9] * 9\n",
    "\n",
    "modelo_ga2= GaussianNB(priors=priors)\n",
    "modelo_ga2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluar_modelo(modelo_ga2, X_test, y_test, metrica=\"f1_macro\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clasificador(tipo_clasificador=\"LogisticRegression\", ruta_salida=\"modelo_lg.pkl\", datos_entrenar=(X_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"modelo_lg.pkl\", \"rb\") as modelo_rl:\n",
    "    modelo_rl=pickle.load(modelo_rl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluar_modelo(modelo_rl, X_test, y_test, metrica=\"f1_macro\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "prueba de modelos de regresión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistica_ajustada = LogisticRegression(penalty='l1', solver= \"liblinear\", class_weight='balanced')\n",
    "logistica_ajustada.fit(X_train, y_train)\n",
    "\n",
    "evaluar_modelo(logistica_ajustada, X_test, y_test, metrica=\"f1_weighted\")\n",
    "\n",
    "#Este modelo rinde bien con las clases grandes, pero falla con las minoritarias. con un f1_macro de 0.42 y un f1 f1_weighted cercano al 90 %, podemos decir que es un modelo regular. predice bien las clases con mayor frecuencia, pero falla en las minoritarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#logistica_ajustada2 = LogisticRegression(penalty='l2', solver= \"liblinear\", class_weight='balanced')\n",
    "#logistica_ajustada2.fit(X_train, y_train)\n",
    "\n",
    "evaluar_modelo(logistica_ajustada2, X_test, y_test, metrica=\"f1_macro\")\n",
    "\n",
    "#Este tiene el mismo problema que el anterior. buena capacidad general, pero bajo rendimiento cuando se trata de específicas. 0.89 y f1_macro de 0.42 lo demuestran."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#logistica_ajustada3 = LogisticRegression(penalty='elasticnet', solver= 'saga', l1_ratio=0.5, class_weight='balanced', C=1.0, random_state=30)\n",
    "#logistica_ajustada3.fit(X_train, y_train)\n",
    "\n",
    "evaluar_modelo(logistica_ajustada3, X_test, y_test, metrica=\"reporte_clasificacion\")\n",
    "\n",
    "#Este tiene un menor rendimiento, tanto en f1_macro como en f1_weighted, 0.33en el primero y 0.74 en el segundo. Peor rendimiento hasta el momento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En general y luego de haber analizado varios modelos con distintos parámetros, el que tiene mejor rendimiento es la regresión logística por defecto. Si bien se experimentan cambios al ajustar ciertos parámetros como le penalización, el rendimiento general se mantiene. En general predice bien las clases mayoritarias, pero le cuesta mucho en aquellas donde no hay tantos datos."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
